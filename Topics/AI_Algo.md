# Complete List of Machine Learning, AI, and Deep Learning Algorithms

## Table of Contents
1. [Supervised Learning Algorithms](#supervised-learning)
2. [Unsupervised Learning Algorithms](#unsupervised-learning)
3. [Reinforcement Learning Algorithms](#reinforcement-learning)

---

## SUPERVISED LEARNING ALGORITHMS

### Regression Algorithms
- Linear Regression
- Logistic Regression
- Ridge Regression
- Lasso Regression
- Elastic Net Regression
- Polynomial Regression
- Support Vector Regression (SVR)
- Decision Tree Regressor
- K-Nearest Neighbors Regressor (KNN Regressor)
- Random Forest Regressor
- Gradient Boosting Regressor
- AdaBoost Regressor
- XGBoost Regressor
- LightGBM Regressor
- CatBoost Regressor
- Neural Network Regressor (MLP Regressor)

### Classification Algorithms
- Logistic Regression
- Decision Trees
- Random Forest
- Support Vector Machine (SVM)
- Naive Bayes
- K-Nearest Neighbors (KNN)
- Gradient Boosting Machines (GBM)
- XGBoost (Extreme Gradient Boosting)
- AdaBoost (Adaptive Boosting)
- LightGBM (Light Gradient Boosting Machine)
- CatBoost (Categorical Boosting)
- Linear Discriminant Analysis (LDA)
- Quadratic Discriminant Analysis (QDA)
- Neural Networks (Multilayer Perceptron - MLP)
- Gaussian Process Classifier
- Extra Trees Classifier (Extremely Randomized Trees)
- Stochastic Gradient Descent (SGD) Classifier

### Ensemble Methods (Supervised)
- Bagging
- Bootstrap Aggregating
- Boosting
- Stacking
- Voting Classifiers
- Blending

---

## UNSUPERVISED LEARNING ALGORITHMS

### Clustering Algorithms
- K-Means
- K-Medoids
- Hierarchical Clustering (Agglomerative & Divisive)
- DBSCAN (Density-Based Spatial Clustering of Applications with Noise)
- OPTICS (Ordering Points To Identify the Clustering Structure)
- Gaussian Mixture Models (GMM)
- Fuzzy C-Means
- Mean Shift
- Affinity Propagation
- Spectral Clustering
- BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies)
- Self-Organizing Maps (SOM)

### Dimensionality Reduction Algorithms
- Principal Component Analysis (PCA)
- Singular Value Decomposition (SVD)
- t-Distributed Stochastic Neighbor Embedding (t-SNE)
- Locally Linear Embedding (LLE)
- Isomap
- Multidimensional Scaling (MDS)
- Independent Component Analysis (ICA)
- Factor Analysis
- Feature Extraction Techniques
- Autoencoders
- Variational Autoencoder (VAE)

### Anomaly Detection Algorithms
- Isolation Forest
- Local Outlier Factor (LOF)
- One-Class SVM
- Minimum Covariance Determinant (MCD)
- Gaussian Mixture Models (GMM)
- K-Nearest Neighbors (KNN) for Anomaly Detection

### Association Rule Learning Algorithms
- Apriori
- Eclat (Equivalence Class Transformation)
- FP-Growth (Frequent Pattern Growth)

### Density Estimation Algorithms
- Kernel Density Estimation (KDE)
- Gaussian Mixture Models (GMM)
- Parzen Windows

---

## DEEP LEARNING ALGORITHMS

### Feedforward Neural Networks
- Multilayer Perceptron (MLP)
- Deep Neural Networks (DNN)
- Feedforward Neural Network (FFNN)
- Fully Connected Networks (FCN)

### Convolutional Neural Networks (CNN)
- Basic CNN
- AlexNet
- VGG (Visual Geometry Group)
- ResNet (Residual Networks)
- Inception Network
- MobileNet
- EfficientNet
- SqueezeNet
- DenseNet
- U-Net

### Recurrent Neural Networks (RNN)
- Vanilla RNN
- Long Short-Term Memory (LSTM)
- Gated Recurrent Unit (GRU)
- Bidirectional LSTM (BiLSTM)
- Bidirectional GRU (BiGRU)
- Peephole LSTM
- Clockwork RNN

### Attention-Based Models
- Transformer
- Self-Attention Mechanism
- Multi-Head Attention
- BERT (Bidirectional Encoder Representations from Transformers)
- GPT (Generative Pre-trained Transformer)
- Vision Transformer (ViT)
- T5 (Text-to-Text Transfer Transformer)
- RoBERTa (Robustly Optimized BERT Pretraining Approach)

### Generative Models
- Generative Adversarial Network (GAN)
- Deep Convolutional GAN (DCGAN)
- StyleGAN
- CycleGAN
- Pix2Pix
- Variational Autoencoder (VAE)
- Adversarial Autoencoder (AAE)
- Multi-Adversarial Autoencoder (MAAE)
- PixelCNN
- WaveNet
- NeRF (Neural Radiance Fields)

### Restricted Models
- Restricted Boltzmann Machine (RBM)
- Deep Belief Network (DBN)
- Boltzmann Machine

### Autoencoders and Variants
- Autoencoder
- Denoising Autoencoder
- Sparse Autoencoder
- Variational Autoencoder (VAE)
- Convolutional Autoencoder
- Stacked Autoencoder
- Adversarial Autoencoder (AAE)

### Sequence-to-Sequence Models
- Encoder-Decoder Architecture
- Sequence-to-Sequence (Seq2Seq) with Attention
- Neural Machine Translation (NMT)
- ULMFiT (Universal Language Model Fine-Tuning)

### Graph Neural Networks
- Graph Convolutional Network (GCN)
- Graph Attention Network (GAT)
- Graph Isomorphism Network (GIN)
- GraphSAGE (Graph SAmple and aggreGatE)
- Message Passing Neural Network (MPNN)

### Temporal/Time Series Models
- Temporal Convolutional Network (TCN)
- WaveNet
- Temporal Fusion Transformer
- N-BEATS (Neural Basis Expansion Analysis with Time Series)

### Transfer Learning & Fine-tuning
- Pre-trained Models
- Fine-tuning Approaches
- Domain Adaptation Networks

---

## REINFORCEMENT LEARNING ALGORITHMS

### Value-Based Methods
- Q-Learning
- Deep Q-Networks (DQN)
- Double DQN (DDQN)
- Dueling DQN
- Prioritized Experience Replay (PER)
- Rainbow DQN
- Expected Sarsa
- Deep Deterministic Policy Gradient (DDPG)

### Policy-Based Methods
- REINFORCE
- Policy Gradient
- Trust Region Policy Optimization (TRPO)
- Proximal Policy Optimization (PPO)
- Actor-Critic (AC)
- Advantage Actor-Critic (A2C)
- Asynchronous Advantage Actor-Critic (A3C)
- Soft Actor-Critic (SAC)
- Twin Delayed DDPG (TD3)
- Deterministic Policy Gradient (DPG)
- Deep Deterministic Policy Gradient (DDPG)

### Actor-Critic Methods
- Actor-Critic (AC)
- Advantage Actor-Critic (A2C)
- Asynchronous Advantage Actor-Critic (A3C)
- Deep Deterministic Policy Gradient (DDPG)
- Twin Delayed DDPG (TD3)
- Soft Actor-Critic (SAC)
- Proximal Policy Optimization (PPO)
- Trust Region Policy Optimization (TRPO)

### Model-Based Methods
- Dyna-Q
- World Models
- Model-Predictive Control (MPC)
- Imagination-Augmented Agents
- I2A (Imagination-Augmented Agents)

### Multi-Agent Reinforcement Learning
- QMIX (Mixing Networks for Multi-Agent Q-Learning)
- MARL (Multi-Agent Reinforcement Learning)
- MADDPG (Multi-Agent DDPG)
- MAPPO (Multi-Agent PPO)

### Inverse Reinforcement Learning
- Maximum Entropy IRL
- Apprenticeship Learning
- Guided Cost Learning

### Hierarchical Reinforcement Learning
- Options Framework
- Feudal Networks
- HAMs (Hierarchical Abstract Machines)

### Exploration Methods
- Epsilon-Greedy
- Upper Confidence Bound (UCB)
- Thompson Sampling
- Curiosity-Driven Learning
- Intrinsic Motivation

---

## DETAILED TABULAR SUMMARY

| Category | Algorithm Name | Type | Primary Use Case |
|----------|---|---|---|
| **SUPERVISED** | Linear Regression | Regression | Continuous value prediction |
| | Logistic Regression | Classification | Binary/Multi-class classification |
| | Decision Tree | Both | Classification and Regression |
| | Random Forest | Both | Classification and Regression |
| | Support Vector Machine (SVM) | Both | Classification and Regression |
| | Naive Bayes | Classification | Text classification, Spam detection |
| | K-Nearest Neighbors (KNN) | Both | Classification and Regression |
| | Gradient Boosting | Both | Classification and Regression |
| | XGBoost | Both | Classification and Regression |
| | AdaBoost | Both | Classification and Regression |
| | Neural Networks (MLP) | Both | Complex non-linear problems |
| | LightGBM | Both | Large-scale Classification/Regression |
| | CatBoost | Both | Categorical feature handling |
| **UNSUPERVISED** | K-Means | Clustering | Customer segmentation |
| | Hierarchical Clustering | Clustering | Hierarchical data organization |
| | DBSCAN | Clustering | Arbitrary shape clustering |
| | Gaussian Mixture Models | Clustering | Probabilistic clustering |
| | Principal Component Analysis (PCA) | Dimensionality Reduction | Feature reduction |
| | t-SNE | Dimensionality Reduction | Data visualization |
| | Isolation Forest | Anomaly Detection | Outlier detection |
| | Apriori | Association Learning | Market basket analysis |
| | Autoencoders | Dimensionality Reduction | Feature learning |
| **DEEP LEARNING** | CNN | Image Processing | Computer vision tasks |
| | RNN | Sequence Processing | Time series, NLP |
| | LSTM | Sequence Processing | Long-term dependencies |
| | GRU | Sequence Processing | Efficient sequence processing |
| | Transformer | Sequence Processing | NLP, Machine translation |
| | GAN | Generative | Image generation |
| | VAE | Generative | Data generation |
| | BERT | NLP | Text understanding |
| | GPT | NLP | Text generation |
| **REINFORCEMENT** | Q-Learning | Value-Based | Game playing, Control |
| | Deep Q-Networks (DQN) | Value-Based | Atari games, Complex control |
| | Policy Gradient | Policy-Based | Continuous control |
| | Actor-Critic (A2C/A3C) | Actor-Critic | Balanced exploration/exploitation |
| | PPO | Policy-Based | Robotics, Game AI |
| | DDPG | Actor-Critic | Continuous control tasks |
| | SAC | Actor-Critic | Continuous action spaces |

---

## QUICK REFERENCE BY LEARNING TYPE

### Supervised Learning (Labeled Data)
**Count: 80+ algorithms**
- Regression (16+), Classification (17+), Ensemble Methods (6+)

### Unsupervised Learning (Unlabeled Data)
**Count: 50+ algorithms**
- Clustering (12+), Dimensionality Reduction (10+), Anomaly Detection (6+), Association Learning (3+), Density Estimation (3+)

### Deep Learning (Neural Network-Based)
**Count: 70+ algorithms/architectures**
- CNNs (10+), RNNs/LSTMs/GRUs (8+), Transformers (8+), GANs (8+), Autoencoders (7+), Graph Networks (5+), Temporal Models (4+)

### Reinforcement Learning
**Count: 40+ algorithms**
- Value-Based (8+), Policy-Based (8+), Actor-Critic (8+), Model-Based (4+), Multi-Agent (4+), Hierarchical (3+), Exploration (5+)

**Total Comprehensive Coverage: 240+ Machine Learning & AI Algorithms**

---

## NOTES

1. **Overlap Categories**: Some algorithms appear in multiple categories (e.g., Neural Networks in both Supervised and Deep Learning)
2. **Variants**: Many algorithms have multiple variants and improvements (e.g., LSTM has Bidirectional LSTM, Peephole LSTM)
3. **Hybrid Approaches**: Modern applications often combine multiple algorithms (e.g., CNN-LSTM for video processing)
4. **Emerging Methods**: New algorithms and variants are continuously being developed
5. **Implementation**: Most algorithms have multiple implementations available in libraries like scikit-learn, TensorFlow, PyTorch, and Keras

---

## LIBRARY REFERENCES

- **Scikit-learn**: Most supervised and unsupervised algorithms
- **TensorFlow/Keras**: Deep learning and neural networks
- **PyTorch**: Deep learning and custom architectures
- **XGBoost, LightGBM, CatBoost**: Gradient boosting variants
- **OpenAI Gym**: Reinforcement learning environments
- **Stable Baselines3**: RL algorithm implementations
